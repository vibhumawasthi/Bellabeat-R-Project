---
title: "Bellabeat"
author: "Vibhum"
date: "2024-04-28"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Bellabeat is a high-tech manufacturer of health-focused products for women. It is a successful small company, who has the potential to become a larger player in the global smart device market.

1. founded in 2013
2. manufactures health-focused smart products
3. develops beautifully designed technology
4. positions itself as a tech-driven wellness company for women


## Step 1. ASK

The business task is to identify how consumers use non-Bellabeat smart devices. The findings will be applied to Bellabeat’s marketing strategy.

Stakeholders are:

1. Cofounders
  Urška Sršen and Sando Mur 
  
2. Marketing analytics team

## Step 2. PREPARE
For analysis, I am going to use Fitbit Fitness Tracker Data available through Mobius and stored at Kaggle. The dataset was generated by respondents to a distributed survey via Amazon Mechanical Turk between 04.12.2016-05.12.2016. 
It contains data from 30 Fitbit users who consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring.

## Step 3. PROCESS
Given the complexity and size of the dataset, I chose a programming language R as a tool for data processing, making it the optimal choice over SQL and spreadsheets for comprehensive analysis and interpretation. Moreover, it allows for immediate result visualisation, making it even more convenient.

I started away by loading the following libraries to manipulate the data:

  tidyverse, skimr, janitor 
  
```{r}
install.packages("tidyverse")
install.packages("skimr")
install.packages("janitor")
```
  
  
```{r}
library(tidyverse)
library(skimr)
library(janitor)
```

### Data exploration
I begin the data exploration by importing relevant datasets:
```{r}
# use read.csv() function to import CSV files (set header argument to TRUE as first rows of csv files contain column names)
daily_activity <- read.csv("/cloud/project/dailyActivity_merged.csv", header = TRUE)
daily_steps <- read.csv("/cloud/project/dailySteps_merged.csv", header = TRUE)
hourly_steps <- read.csv("/cloud/project/hourlySteps_merged.csv", header = TRUE)
daily_calories <- read.csv("/cloud/project/dailyCalories_merged.csv", header = TRUE)
hourly_calories <- read.csv("/cloud/project/hourlyCalories_merged.csv", header = TRUE)
daily_sleep <- read.csv("/cloud/project/sleepDay_merged.csv", header = TRUE)
```

Next, I will preview the data:

```{r}
# use head() function to display the first few rows of data frames
head(daily_activity)
head(daily_steps)
head(hourly_steps)
head(daily_calories)
head(hourly_calories)
head(daily_sleep)
```

```{r}
# use str() function to display the internal structure of data frames
str(daily_activity)
str(daily_steps)
str(hourly_steps)
str(daily_calories)
str(hourly_calories)
str(daily_sleep)
```
Athough the data frames already contain the column names, I would like to view them separately, without any additional information, for a clearer understanding

```{r}
# use colnames() function to return the names of the columns in data frames
colnames(daily_activity)
colnames(daily_steps)
colnames(hourly_steps)
colnames(daily_calories)
colnames(hourly_calories)
colnames(daily_sleep)
```

Referring to the Fitbit Fitness Tracker Data description, it states that the dataset contains data from 30 users. Now, let's determine the number of participants in each data frame.

```{r}
# use n_distinct() function to count the number of unique values within a set of vectors
# also, in this context n_unique() function can be used to calculate the number of unique elements
n_distinct(daily_activity$Id)
n_distinct(daily_activity$Id)
n_distinct(daily_activity$Id)
n_distinct(daily_calories$Id)
n_distinct(hourly_calories$Id)
n_distinct(daily_sleep$Id)
```

It turns out that there are more participants than initially indicated in the Fitbit data description. Also, not all datasets contain the same number of participants. Specifically, there is sleep data available for only 24 users, while others have data for 33 users. How you handle this difference in participant numbers depends on your analysis goals.

### Data cleaning

Now, it is time to clean up the data. First, I will check for any duplicates in the data frames.

```{r}
# use sum(duplicated()) function to see the total count of duplicated rows in the data frames
sum(duplicated(daily_activity))
sum(duplicated(daily_steps))
sum(duplicated(hourly_steps))
sum(duplicated(daily_calories))
sum(duplicated(hourly_calories))
sum(duplicated(daily_sleep))
```

In the daily_sleep data frame there are duplicates. Therefore, in the next step I will eliminate them.

```{r}
# use distinct() function to delete the duplicate values. Next, add assignment operator "<-" to assign value to the variable. Without doing this, any further operations or analysis on daily_sleep will still consider the original dataset with duplicates, and the sum of duplicated values will be calculated based on the original dataset, not the one with duplicates removed. In this content as well as before instead of distinct() could be used unique() function
# use sum() function to verify that duplicates are removed
daily_sleep <- distinct(daily_sleep)
sum(duplicated(daily_sleep))
```

Following that, I will check if there are any missing values in the data frames

```{r}
# use %>% operator for piping data into a sequence of operations
# use sum(is.na()) function to count the number of missing values in each column
# use summarise_all() to apply previous function to each column of the data frame
missing_values1 <- daily_activity %>%
  summarise_all(~sum(is.na(.)))

# then, use if-else statement to check if there are any missing values 
if (any(missing_values1 > 0)) {
  # print summary of missing values
  print(missing_values1)
} else {
  # print message if no missing values
  print("No missing values in daily_activity data frame")
}


# the same operations will be applied to the rest of the data frames

missing_values2 <- daily_steps %>%
  summarise_all(~sum(is.na(.)))

if (any(missing_values2 > 0)) {
  print(missing_values2)
} else {
  print("No missing values in daily_steps data frame")
}

missing_values3 <- hourly_steps %>%
  summarise_all(~sum(is.na(.)))

if (any(missing_values3 > 0)) {
  print(missing_values3)
} else {
  print("No missing values in hourly_steps data frame")
}

missing_values4 <- daily_calories %>%
  summarise_all(~sum(is.na(.)))

if (any(missing_values4 > 0)) {
  print(missing_values4)
} else {
  print("No missing values in daily_calories data frame")
}

missing_values5 <- hourly_calories %>%
  summarise_all(~sum(is.na(.)))

if (any(missing_values5 > 0)) {
  print(missing_values5)
} else {
  print("No missing values in hourly_calories data frame")
}

missing_values6 <- daily_sleep %>%
  summarise_all(~sum(is.na(.)))

if (any(missing_values6 > 0)) {
  print(missing_values6)
} else {
  print("No missing values in daily_sleep data frame")
}
```

If there were missing values in the data frames, I could use the drop_na function to remove them.

Next, I will format the data.

```{r}
# use clean_names() function to clean column names by converting them to lowercase, removing special characters, and replacing spaces with underscores
daily_activity <- clean_names(daily_activity)
daily_steps <- clean_names(daily_steps)
hourly_steps <- clean_names(hourly_steps)
daily_calories <- clean_names(daily_calories)
hourly_calories <- clean_names(hourly_calories)
daily_sleep <- clean_names(daily_sleep)

# use head() to review updated dataframes
head(daily_activity)
head(daily_steps)
head(hourly_steps)
head(daily_calories)
head(hourly_calories)
head(daily_sleep)
```

To ensure consistency across data frames, it is necessary to standardise all columns containing dates and times to the same format. There are 6 data frames in total:

3 of these data frames have columns with dates, but the names of these columns are different from each other (specifically, daily_activity, daily_steps, daily_calories)
the other 3 have columns with both dates and times, but once again, the column names differ (specifically, hourly_steps, hourly_calories, daily_sleep)
I will start with the data frames that have only date columns.

```{r}
# use colnames() function to change the name of the column
colnames(daily_activity)[2] <- "date"
colnames(daily_steps)[2] <- "date"
colnames(daily_calories)[2] <- "date"

# use head() to review updated dataframes
head(daily_activity)
head(daily_steps)
head(daily_calories)
```

Next, I will proceed to format the remaining 3 data frames where date and time are combined in the same column.

```{r}
# use separate() function to split a table column into multiple columns
# use into argument and its argument c to specify the names of the new columns that will be created after splitting the original column
# use sep argument to separate the original column into multiple columns
hourly_steps <- hourly_steps %>%
  separate(activity_hour, into = c("date", "time"), sep = " ")

hourly_calories <- hourly_calories %>%
  separate(activity_hour, into = c("date", "time"), sep = " ")

daily_sleep <- daily_sleep %>%
  separate(sleep_day, into = c("date", "time"), sep = " ")

# use head() to review updated dataframes
head(hourly_steps)
head(hourly_calories)
head(daily_sleep)
```

The warning means that some values in the original date-time column do not match the expected format, for example, some time formats also include the AM or PM time period. However, since only the daily_sleep dataset and its specified dates will be used for further analysis, this warning can be ignored.

From the original Fitbit dataset, I have selected 6 data frames. As I proceed to the analysis step, I have chosen to focus on 3 of them:

daily_activity
daily_calories
daily_sleep Let's take another look at them.

```{r}
# use head() function to display the first rows of data frames
head(daily_activity)
head(daily_calories)
head(daily_sleep)
```
Let's take a look at a brief summary of these data frames.

```{r}
# use select() function to select specific columns from a dataframe
# use summary() function to generate summary statistics for the selected columns
daily_activity %>%
select(total_steps,
total_distance,
sedentary_minutes) %>%
summary()
```
Now let's see its visualisation.

```{r}
# use ggplot() function to build the initial plot object, set the data and aesthetics
# use geom_point() function to create a scatterplot
ggplot(data=daily_activity, aes(x=total_steps, y=sedentary_minutes)) + geom_point()
```

I will perform the same operations on the remaining two data frames.

```{r}
# use select() function to select specific columns from a dataframe
# use summary() function to generate summary statistics for the selected columns
daily_calories %>%
select(calories) %>%
summary()
```

```{r}
# use ggplot() function to build the initial plot object, set the data and aesthetics
# use geom_point() function to create a scatterplot
ggplot(data=daily_calories, aes(x=date, y=calories)) + geom_point()
```

This graph is not informative no matter which plot is used because the dataset has only 3 attributes two of which are user ID and date

```{r}
# use select() function to select specific columns from a dataframe
# use summary() function to generate summary statistics for the selected columns
daily_sleep %>%
select(total_sleep_records,
total_minutes_asleep,
total_time_in_bed) %>%
summary()
```

```{r}
# use ggplot() function to build the initial plot object, set the data and aesthetics
# use geom_point() function to create a scatterplot
ggplot(data=daily_sleep, aes(x=total_minutes_asleep, y=total_time_in_bed)) + geom_point()
```

### Data merging
After reviewing the summary of the data frames and understanding the relationships between their attributes, it is time to merge them into a unified dataset based on user ID and date.

```{r}
# use merge() function to merge two or more dataframes in R based on common columns. Since there are more than two data frames to merge, use x and y which determine the specific data frames involved in each merge operation
# use argument by to specify the columns to merge on
# use all = TRUE parameter in the merge() function to indicate that a full outer join should be performed
combined_data <- merge(x = merge(x = daily_activity, y = daily_calories, by = c("id", "date"), all = TRUE), 
                     y = daily_sleep, by = c("id", "date"), all = TRUE)
# use n_distinct() function to count the number of unique values in a set of vectors
n_distinct(combined_data$id)
# use head() function to display the first rows of the data frame
head(combined_data)
```

I noticed that the merged table has 2 columns with calories values. I will verify if the values match and, if so, remove the duplicate column.

```{r}
# use if-else statement to show the result of comparing two columns
# use all() function to determine if all the values in calories.x are equal to the corresponding values in calories.y
if(all(combined_data$calories.x == combined_data$calories.y)) {
  # If they are similar, remove one of them
  combined_data <- combined_data[, -which(names(combined_data) == "calories.y")]
} else {
  # If they are not similar, print a message indicating so
  print("The two columns have different values.")
}

# use names() function to set the name of an object. Also, colnames() could be used
names(combined_data)[names(combined_data) == "calories.x"] <- "calories"

# use head() function to display the first rows of the data frame
head(combined_data)
```

Once data merging is done, cleaning should be performed again. At least, I will check if there are no duplicates.

```{r}
# use sum(duplicated()) function to see the total count of duplicated rows in the data frame
sum(duplicated(combined_data))
```
I will take another look at the merged data frame.

```{r}
# use glimpse() function to provide a concise overview of a dataframe. It is like a transposed version of print(): columns run down the page, and data runs across
glimpse(combined_data)
```
## Step 4. ANALYSE
For analysis I would like to group Fitbit users to identify patterns, perform comparative analysis and subsequently provide more personalised insights. The resulting merged data frame has four attributes:

sedentary_minutes < 5000
lightly_active_minutes >= 5000, but <= 7499
fairly_active_minutes >= 7500, but <= 9999
very_active_minutes >= 10000

```{r}
# use group_by() function to group the data by the id column
# use summarise() function to calculate summary statistics within each group defined below
# use mean() function to calculate average number of steps
# use mutate() function to create a new column named "user type"
# use case_when() function to categorise users based on their average daily steps into different activity levels
daily_average_steps <- combined_data %>%
  group_by(id) %>%
  summarise(daily_steps = mean(total_steps)) %>%
  mutate(activity_level = case_when(
    daily_steps >= 1 & daily_steps < 5000 ~ "sedentary",
    daily_steps >= 5000 & daily_steps <= 7499 ~ "lightly_active", 
    daily_steps >= 7500 & daily_steps <= 9999 ~ "fairly_active",
    daily_steps >= 10000 ~ "very_active",
  ))

# use head() function to display the first rows of the data frame
head(daily_average_steps)
```
I will now calculate the percentage of activity levels among users.
```{r}
# use group_by() fucntion to group the data by activity level
# use summarise() function to calculates the number of users at each level
# use mutate() function to add a new column
activity_level <- daily_average_steps %>%
  group_by(activity_level) %>% 
  summarise(total_users_at_level = n()) %>% 
  mutate(total_users = sum(total_users_at_level)) %>% 
  mutate(total_percent = total_users_at_level / total_users)  %>% 
  mutate(percent = scales::percent(total_percent))

# use head() function to display the first rows of the data frame
head(activity_level)
```
Next, let's visualise the proportion of activity level.

```{r}
# use ggplot() function to construct the initial plot object
# use + operator to combine different layers of the plot
# use geom_bar() function to create a bar plot
# use coord_polar() function to transform the bar plot into a pie chart
# use theme_void() function to remove most of the background, gridlines, and text, making the plot minimalistic, which is suitable for a pie chart
# use labs() function to add a main title and a legend title to the plot
# use geom_text() function to add text labels to each slice of the pie chart
# use theme() function to modify the appearance of the plot title
# use scale_fill_brewer() function to apply color schemes from the RColorBrewer package to the fill aesthetic of the plot
ggplot(activity_level, aes(x = "", y = total_percent, fill = activity_level)) + 
  geom_bar(width = 1, stat = "identity", color = "white") + 
  coord_polar("y", start = 0) + 
  labs(title = "Activity level distribution", fill = "Activity level") +
  geom_text(aes(label = percent), position = position_stack(vjust = 0.5)) +
  theme_void() +  
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold")) +
  scale_fill_brewer(palette = "Set2")
```

The graph illustrates that the differences between activity levels are not pronounced.

As the next step, I will analyse the distribution of step counts throughout the week.

```{r}
# first, use mdy() function to convert date column from character to a date object
# use wday() function to extract the day of the week from the date column. Also, apply label=TRUE argument to display the day of the week as text, and week_start=1 to indicate that week starts on Monday
combined_data$date <- mdy(combined_data$date)
combined_data$day_of_week <- wday(combined_data$date, label = TRUE, week_start = 1)

# use group_by() function to group the data by the day of the week
# use summarise() function to calculate the average of the total_steps column for each day of the week
average_steps_day_of_week <- combined_data %>%
  group_by(day_of_week) %>%
  summarise(avg_steps = mean(total_steps))

# use print() function to display results
print(average_steps_day_of_week)
```
Numbers are good, but I need visualisation for better understanding.

```{r}
# use ggplot() function to initialise a ggplot object
# use + operator to combine different layers of the plot
# use geom_col() function to create a bar plot with vertical bars
# use geom_hline() function to add a horizontal line to the plot and apply yintercept argument to set y coordinate where the line appear
# use labs() function to set the labels for the plot
# use theme_minimal to apply a minimalistic theme to the plot
ggplot(average_steps_day_of_week, aes(x = day_of_week, y = avg_steps)) +
  geom_col(fill = "#beaed4") +
  geom_hline(yintercept = 7500, linetype = "dashed", color = "red", size = 1) +
  labs(title = "Average steps per day",
       x = "Day of the week",
       y = "Average steps") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))
```
Then, I would like to examine how average sleep time varies with each day of the week.
A consensus recommendation for the amount of sleep needed for optimal adult health is 7 to 9 hours. I will refer to this data when evaluating sleep duration.

```{r}
# use group_by() function to group the data by the day of the week
# use summarise() function to calculate the average of the total_steps column for each day of the week. Include na.rm = TRUE argument to remove missing values from the calculation
average_sleep_day_of_week <- combined_data %>%
  group_by(day_of_week) %>%
  summarise(avg_sleep = mean(total_minutes_asleep,  na.rm = TRUE))

# use print() function to display results
print(average_sleep_day_of_week)
```
I will make a visualisation to see if the resulting values fall within the recommended values (7-9 hours, i.e. 420-540 minutes).

```{r}
# use ggplot() function to initialise the ggplot object
# use + operator to combine different layers of the plot
# use geom_col() function to create a bar plot with vertical bars
# use geom_hline() function to add a horizontal line to the plot and apply yintercept argument to set y coordinate where the line appear
# use labs() function to set the labels for the plot
# use theme_minimal to apply a minimalistic theme to the plot
ggplot(average_sleep_day_of_week, aes(x = day_of_week, y = avg_sleep)) +
  geom_col(fill = "#80b1d3") +
  geom_hline(yintercept = 540, linetype = "dashed", color = "seagreen", size = 1) +
  geom_hline(yintercept = 420, linetype = "dashed", color = "red", size = 1) +
  labs(title = "Average sleep per day",
       x = "Day of the week",
       y = "Average min of sleep") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))
```
Next, I am going to study the correlation between steps and calories per day.

```{r}
# use ggplot() function to initialise the ggplot object
# use + operator to combine different layers of the plot
# use geom_point() function to create a scatter plot
# use geom_smooth() function to add a regression line to the plot
# use labs() function to set the title of the plot and labels for the x-axis and the y-axis
# use theme() function to set the theme of the plot (title position, font size, bold face)
ggplot(combined_data, aes(x = total_steps, y = calories)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Calories vs Total steps",
       x = "Total steps",
       y = "Calories") +
  theme(plot.title = element_text(hjust = 0.5, size = 20, face = "bold"))
```
It would be interesting to examine how the correlations vary across different levels of activity.
```{r}
# use left_join() function to join two data frames based on the same column
combined_data_with_steps <- left_join(combined_data, daily_average_steps, by = "id")

# use ggplot() function to initialise the ggplot object
# use + operator to combine different layers of the plot
# use geom_point() function to create a scatter plot
# use geom_smooth() function to add a regression line to the plot
# use labs() function to set the title of the plot and labels for the x-axis and the y-axis
# use scale_color_brewer() function to specify the color palette for discrete data mapped to a color aesthetic in a plot
# use theme() function to set the theme of the plot (title position, font size, bold face)
ggplot(combined_data_with_steps, aes(x = total_steps, y = calories, color = activity_level)) +
  geom_point() +
  geom_smooth() +
  labs(title = "Calories vs Total steps at different activity levels", x = "Total Steps", y = "Calories", color = "Activity level") +
  scale_color_brewer(palette = "Set2") +
  theme(plot.title = element_text(hjust = 0.4, size = 20, face = "bold"))
```
```{r}
# use group_by() function to group the data by activity level
# use summarise() function to calculates the correlation coefficient at each activity level using the cor() function
cor_coefficients <- combined_data_with_steps %>%
  group_by(activity_level) %>%
  summarise(correlation = cor(total_steps, calories))

# use print() function to see the Pearson correlation coefficient at different activity level
print(cor_coefficients)
```

There is a positive correlation between total steps and calories across all activity levels. It is worth noting that the correlation between total steps and calories is higher at the sedentary level than at the fairly active level.

## Step 5. SHARE
Moving on to the final stage of the case study. I first present the findings of Fitbit data analysis.

Findings

The data reveals that a significant portion of users are categorised as "fairly active" or "lightly active" (27.3% each), while fewer users fall into the "sedentary" (24.2%) or "very active" (21.2%) categories. Each activity level group consists of 7 to 9 users out of a total of 33, indicating a relatively consistent group size distribution.

Throughout the week, users on average exceed the recommended daily step count of 7500. However, there's a noticeable decline towards the end of the working week, particularly on Thursday and Friday, as well as on Sunday. This decline is followed by a significant increase in step count on Saturday, where values are the highest. This pattern suggests a potential trend of reduced physical activity as the week progresses, possibly influenced by weekday routines or work-related factors, with weekends providing more opportunities for increased physical activity.

The data shows variations in average sleep duration across different days of the week, ranging from 401 to 453 minutes. While some days fall below the recommended minimum sleep duration of 7 hours (420 minutes), particularly Tuesday, Thursday, Friday and Saturday, others equal or slightly exceed it. Specifically, on Wednesday and Sunday, the values slightly exceed the minimum recommended sleep duration, but still are far from the maximum recommended duration of 9 hours (540 minutes).

There is a positive relationship between the total number of steps and calories burned across all activity levels. The strength of this relationship varies, with "very active" individuals showing the strongest positive correlation, followed by "lightly active," "sedentary," and "fairly active". Increasing physical activity, as measured by steps taken, tends to result in a higher calorie expenditure.


## Step 6. ACT

In the final step, I will share my recommendations to stakeholders, which will help guide marketing strategy for Bellabeat.

It's important to note that these recommendations are not women-centered, as the analysis is based on gender-free data. 

Additionally, when defining the business task, it was emphasised that the focus should center on one of the Bellabeat's products. Given that Bellabeat app connects and manages all its products, the following recommendations are specifically tailored for it.

Recommendations


Develop tailored messages within the app that resonate with specific user types, highlighting how the app can assist them in achieving their health goals.

Provide suggestions on setting personalised working week schedules and hours, and offer tips for incorporating more movement during free time and optimising sleep routines based on individual preferences.
Offer personalised goal setting based on individual activity levels and calorie consumption.

Implement a system of encouraging messages to motivate users when they fall short of reaching their recommended daily step or sleep totals as well as send warning messages to alert users when they deviate from their routine.

Create content for social networks and adds on Youtube and among Google Display Network about basic health habits like reaching daily step goals and maintaining consistent sleep patterns.